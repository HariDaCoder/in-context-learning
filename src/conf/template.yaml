inherit:
  - models/standard.yaml
  - wandb.yaml

model:
  family: gpt2
  n_dims: 20
  n_embd: 256
  n_head: 8
  n_layer: 12
  n_positions: 101

training:
  batch_size: 64
  curriculum:
    dims:
      start: 5
      end: 20
      inc: 1
      interval: 2000
    points:
      start: 11
      end: 41
      inc: 2
      interval: 2000

  # One of: gaussian, sparse_gaussian, ar1, vr1, ar2, vr2, nonstation
  data: gaussian

  # Data kwargs:
  # - When data == 'sparse_gaussian': you may set 'k' (number of non-zero coords).
  # - For other data values: any 'k' key will be ignored automatically.
  data_kwargs: {
    # k: 8        # only when data: sparse_gaussian
    # scale: 1.0  # optional for many samplers
  }

  # Task: choose a base task
  # One of: linear_regression, sparse_linear_regression, linear_classification,
  #         relu_2nn_regression, decision_tree, noisy_linear_regression,
  #         ar1_linear_regression, ar2_linear_regression, non_stationary_linear_regression,
  #         uniform_hypersphere_regression
  task: uniform_hypersphere_regression

  # Task kwargs:
  # - When task == 'sparse_linear_regression': you may set 'sparsity'.
  # - For other tasks: any 'sparsity' key will be ignored automatically.
  task_kwargs:
    noise_std: 0.0
    noise_type: uniform
    w_distribution: gaussian
    w_kwargs:
      scale: 1.0

  learning_rate: 0.0001
  keep_every_steps: 10000
  num_tasks: null
  num_training_examples: null
  resume_id: null
  save_every_steps: 100
  train_steps: 100001

# out_dir: D:\Henry-Projects\ChestXray\how\in-context-learning\models\uniform_hypersphere_regression
out_dir: ../models/noisy_linear_regression

wandb:
    project: "in-context-training"
    name: "w_uniform_hypersphere_gaussian_weights"
    notes: "Training with gaussian-distributed weights (non-uniform on hypersphere)"
    log_every_steps: 100

